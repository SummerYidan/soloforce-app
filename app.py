import streamlit as st
import requests
import json
import re # å¼•å…¥æ­£åˆ™è¡¨è¾¾å¼åº“ï¼Œç”¨æ¥æå– JSON

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="SoloForce AI é¡¾é—® (v2.1)", page_icon="ğŸ§ ", layout="wide")

# --- 2. åˆå§‹åŒ– Session State ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "analysis_done" not in st.session_state:
    st.session_state.analysis_done = False
if "current_scores" not in st.session_state:
    st.session_state.current_scores = None

# --- 3. è¾…åŠ©å‡½æ•°ï¼šå¼ºåŠ› JSON æå–å™¨ (å…³é”®ä¿®å¤) ---
def extract_json(text):
    """
    æ— è®º AI è¿”å›ä»€ä¹ˆä¹±ä¸ƒå…«ç³Ÿçš„æ–‡æœ¬ï¼Œåªæå–ç¬¬ä¸€ä¸ª { åˆ°æœ€åä¸€ä¸ª } ä¹‹é—´çš„å†…å®¹
    """
    try:
        # 1. å°è¯•ç›´æ¥è§£æ
        return json.loads(text)
    except:
        # 2. å¦‚æœå¤±è´¥ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å¯»æ‰¾ JSON å¯¹è±¡
        # å¯»æ‰¾ç¬¬ä¸€ä¸ª '{' å’Œæœ€åä¸€ä¸ª '}'
        match = re.search(r'\{.*\}', text, re.DOTALL)
        if match:
            json_str = match.group()
            try:
                return json.loads(json_str)
            except:
                return None
        return None

# --- 4. ä¾§è¾¹æ é…ç½® ---
with st.sidebar:
    st.title("âš™ï¸ è®¾ç½®")
    api_key = st.text_input("Google Gemini API Key:", type="password")
    
    st.markdown("---")
    st.subheader("ğŸ‘¤ ä½ çš„æ€§æ ¼æ¡£æ¡ˆ")
    mbti_options = ["INTJ (å»ºç­‘å¸ˆ)", "INTP (é€»è¾‘å­¦å®¶)", "ENTJ (æŒ‡æŒ¥å®˜)", "ENTP (è¾©è®ºå®¶)",
                    "INFJ (æå€¡è€…)", "INFP (è°ƒåœè€…)", "ENFJ (ä¸»äººå…¬)", "ENFP (ç«é€‰è€…)",
                    "ISTJ (ç‰©æµå¸ˆ)", "ISFJ (å®ˆå«è€…)", "ESTJ (æ€»ç»ç†)", "ESFJ (æ‰§æ”¿å®˜)",
                    "ISTP (é‰´èµå®¶)", "ISFP (æ¢é™©å®¶)", "ESTP (ä¼ä¸šå®¶)", "ESFP (è¡¨æ¼”è€…)"]
    user_mbti = st.selectbox("é€‰æ‹©ä½ çš„ MBTI äººæ ¼ç±»å‹:", mbti_options, index=0)
    
    # è·å–æ¨¡å‹åˆ—è¡¨
    available_models = []
    if api_key:
        try:
            list_url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}"
            resp = requests.get(list_url)
            if resp.status_code == 200:
                data = resp.json()
                for item in data.get('models', []):
                    if 'generateContent' in item.get('supportedGenerationMethods', []) and 'gemini' in item['name']:
                        available_models.append(item['name'])
        except:
            pass
    
    selected_model_name = "models/gemini-1.5-flash"
    if available_models:
        index = 0
        for i, m in enumerate(available_models):
            if 'flash' in m:
                index = i 
                break
        selected_model_name = st.selectbox("é€‰æ‹©æ¨¡å‹:", available_models, index=index)

# --- 5. ä¸»ç•Œé¢æ ‡é¢˜ ---
st.title("ğŸ§  SoloForce: AI æ·±åº¦åˆ›ä¸šå’¨è¯¢")
st.caption(f"åŸºäº {user_mbti} æ€§æ ¼ç‰¹è´¨çš„ä¸ªæ€§åŒ–åˆ†æä¸æŒ‡å¯¼")

# --- 6. æ ¸å¿ƒ API è°ƒç”¨å‡½æ•° ---
def call_gemini(messages):
    clean_model_name = selected_model_name.replace("models/", "")
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{clean_model_name}:generateContent?key={api_key}"
    headers = {'Content-Type': 'application/json'}
    
    contents_payload = []
    for msg in messages:
        role = "user" if msg["role"] == "user" else "model"
        contents_payload.append({"role": role, "parts": [{"text": msg["content"]}]})
        
    data = {"contents": contents_payload}
    
    try:
        response = requests.post(url, headers=headers, data=json.dumps(data))
        if response.status_code == 200:
            return response.json()['candidates'][0]['content']['parts'][0]['text']
        else:
            return f"Error: {response.status_code} - {response.text}"
    except Exception as e:
        return f"Error: {e}"

# --- 7. åˆå§‹åˆ†æé€»è¾‘ ---
if not st.session_state.analysis_done:
    user_idea = st.text_area("è¾“å…¥ä½ çš„åˆ›ä¸šæƒ³æ³•ï¼š", height=100, placeholder="ä¾‹å¦‚ï¼šæˆ‘æƒ³åšä¸€ä¸ªå¸®åŠ©å†…å‘è€…ç»ƒä¹ æ¼”è®²çš„ VR å·¥å…·...")
    
    if st.button("å¼€å§‹æ·±åº¦åˆ†æ") and api_key and user_idea:
        with st.spinner(f'æ­£åœ¨ç»“åˆ {user_mbti} æ€§æ ¼è¿›è¡Œæ·±åº¦å‰–æ...'):
            
            initial_prompt = f"""
            ä½ æ˜¯ä¸€ä½ç²¾é€šå•†ä¸šåˆ†æå’Œå¿ƒç†å­¦çš„åˆ›ä¸šå¯¼å¸ˆã€‚
            
            ç”¨æˆ·ä¿¡æ¯ï¼š
            - åˆ›ä¸šç‚¹å­ï¼š"{user_idea}"
            - MBTI äººæ ¼ï¼š"{user_mbti}"
            
            è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼Œå¹¶ä¸¥æ ¼ä»¥ JSON æ ¼å¼è¾“å‡ºï¼š
            1. æ‰“åˆ† (market, tech, competition)
            2. analysis_text: è¯¦ç»†è§£é‡Šæ‰“åˆ†ç†ç”±ã€‚
            3. mbti_advice: é’ˆå¯¹è¯¥ MBTI çš„å…·ä½“å»ºè®®ã€‚
            
            JSON æ ¼å¼ç¤ºä¾‹ï¼š
            {{
                "scores": {{ "market": 80, "tech": 50, "competition": 90 }},
                "analysis_text": "åˆ†æå†…å®¹...",
                "mbti_advice": "å»ºè®®å†…å®¹..."
            }}
            """
            
            response_text = call_gemini([{"role": "user", "content": initial_prompt}])
            
            # ğŸ”¥ ä½¿ç”¨æ–°çš„æå–å‡½æ•°
            result_data = extract_json(response_text)
            
            if result_data:
                st.session_state.analysis_done = True
                st.session_state.current_scores = result_data.get('scores', {'market':0, 'tech':0, 'competition':0})
                
                # ä¿å­˜å†å²
                st.session_state.messages.append({"role": "user", "content": f"æˆ‘çš„ç‚¹å­æ˜¯ï¼š{user_idea}ï¼Œæˆ‘æ˜¯ {user_mbti}"})
                
                ai_response_content = f"""
### ğŸ“Š æ·±åº¦è¯„ä¼°æŠ¥å‘Š

**ğŸ’° å¸‚åœºæ½œåŠ›**: {st.session_state.current_scores['market']}/100
**ğŸ› ï¸ æŠ€æœ¯éš¾åº¦**: {st.session_state.current_scores['tech']}/100
**âš”ï¸ ç«äº‰ç¨‹åº¦**: {st.session_state.current_scores['competition']}/100

---
### ğŸ§ ä¸ºä»€ä¹ˆè¿™ä¹ˆæ‰“åˆ†ï¼Ÿ
{result_data.get('analysis_text', 'è§£ææ–‡æœ¬å¤±è´¥')}

---
### ğŸ§˜ ä¸º {user_mbti} å®šåˆ¶çš„åˆ›ä¸šæŒ‡å—
{result_data.get('mbti_advice', 'è§£æå»ºè®®å¤±è´¥')}
                """
                st.session_state.messages.append({"role": "assistant", "content": ai_response_content})
                st.rerun()
            else:
                st.error("åˆ†æç”Ÿæˆäº†ï¼Œä½†æ ¼å¼æœ‰ç‚¹ä¹±ï¼Œæ­£åœ¨é‡è¯•...è¯·å†ç‚¹ä¸€æ¬¡æŒ‰é’®ã€‚")
                with st.expander("æŸ¥çœ‹ AI çš„åŸå§‹å›å¤ (Debugging)"):
                    st.text(response_text)

# --- 8. ç»“æœå±•ç¤ºä¸èŠå¤© ---
else:
    # é¡¶éƒ¨ä»ªè¡¨ç›˜
    if st.session_state.current_scores:
        s = st.session_state.current_scores
        c1, c2, c3 = st.columns(3)
        c1.metric("ğŸ’° å¸‚åœºæ½œåŠ›", f"{s['market']}/100")
        c2.metric("ğŸ› ï¸ æŠ€æœ¯éš¾åº¦", f"{s['tech']}/100")
        c3.metric("âš”ï¸ ç«äº‰ç¨‹åº¦", f"{s['competition']}/100")
        st.markdown("---")

    # èŠå¤©è®°å½•
    for msg in st.session_state.messages:
        if msg["role"] != "user":
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])
        elif msg == st.session_state.messages[0]:
            pass
        else:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

    # èŠå¤©è¾“å…¥
    if prompt := st.chat_input("æƒ³ç»§ç»­è¿½é—®ä»€ä¹ˆï¼Ÿ"):
        with st.chat_message("user"):
            st.markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("assistant"):
            with st.spinner("æ€è€ƒä¸­..."):
                response = call_gemini(st.session_state.messages)
                st.markdown(response)
        st.session_state.messages.append({"role": "assistant", "content": response})

    if st.button("ğŸ”„ å¼€å§‹æ–°çš„åˆ†æ"):
        st.session_state.messages = []
        st.session_state.analysis_done = False
        st.session_state.current_scores = None
        st.rerun()
