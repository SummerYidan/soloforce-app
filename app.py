import streamlit as st
import requests
import json

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="SoloForce AI é¡¾é—® (v2.0)", page_icon="ğŸ§ ", layout="wide")

# --- 2. åˆå§‹åŒ– Session State (è¿™æ˜¯è®©ç½‘é¡µæœ‰è®°å¿†çš„å…³é”®) ---
# å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡æ‰“å¼€ï¼Œåˆå§‹åŒ–èŠå¤©è®°å½•å’Œåˆ†æçŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []
if "analysis_done" not in st.session_state:
    st.session_state.analysis_done = False
if "current_scores" not in st.session_state:
    st.session_state.current_scores = None

# --- 3. ä¾§è¾¹æ é…ç½® (API Key & MBTI) ---
with st.sidebar:
    st.title("âš™ï¸ è®¾ç½®")
    api_key = st.text_input("Google Gemini API Key:", type="password")
    
    st.markdown("---")
    st.subheader("ğŸ‘¤ ä½ çš„æ€§æ ¼æ¡£æ¡ˆ")
    mbti_options = ["INTJ (å»ºç­‘å¸ˆ)", "INTP (é€»è¾‘å­¦å®¶)", "ENTJ (æŒ‡æŒ¥å®˜)", "ENTP (è¾©è®ºå®¶)",
                    "INFJ (æå€¡è€…)", "INFP (è°ƒåœè€…)", "ENFJ (ä¸»äººå…¬)", "ENFP (ç«é€‰è€…)",
                    "ISTJ (ç‰©æµå¸ˆ)", "ISFJ (å®ˆå«è€…)", "ESTJ (æ€»ç»ç†)", "ESFJ (æ‰§æ”¿å®˜)",
                    "ISTP (é‰´èµå®¶)", "ISFP (æ¢é™©å®¶)", "ESTP (ä¼ä¸šå®¶)", "ESFP (è¡¨æ¼”è€…)"]
    user_mbti = st.selectbox("é€‰æ‹©ä½ çš„ MBTI äººæ ¼ç±»å‹:", mbti_options, index=0)
    
    st.info(f"ğŸ’¡ AI å°†ä¼šæ ¹æ® {user_mbti.split(' ')[0]} çš„ç‰¹è´¨ä¸ºä½ å®šåˆ¶åˆ›ä¸šè·¯å¾„ã€‚")

    # è·å–æ¨¡å‹åˆ—è¡¨ (é€»è¾‘åŒä¹‹å‰)
    available_models = []
    if api_key:
        try:
            list_url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}"
            resp = requests.get(list_url)
            if resp.status_code == 200:
                data = resp.json()
                for item in data.get('models', []):
                    if 'generateContent' in item.get('supportedGenerationMethods', []) and 'gemini' in item['name']:
                        available_models.append(item['name'])
        except:
            pass
    
    selected_model_name = "models/gemini-1.5-flash" # é»˜è®¤å€¼
    if available_models:
        # ä¼˜å…ˆæ‰¾ flash æˆ– pro
        index = 0
        for i, m in enumerate(available_models):
            if 'flash' in m:
                index = i 
                break
        selected_model_name = st.selectbox("é€‰æ‹©æ¨¡å‹:", available_models, index=index)

# --- 4. ä¸»ç•Œé¢æ ‡é¢˜ ---
st.title("ğŸ§  SoloForce: AI æ·±åº¦åˆ›ä¸šå’¨è¯¢")
st.caption(f"åŸºäº {user_mbti} æ€§æ ¼ç‰¹è´¨çš„ä¸ªæ€§åŒ–åˆ†æä¸æŒ‡å¯¼")

# --- 5. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° (è°ƒç”¨ API) ---
def call_gemini(messages):
    clean_model_name = selected_model_name.replace("models/", "")
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{clean_model_name}:generateContent?key={api_key}"
    headers = {'Content-Type': 'application/json'}
    
    # æŠŠèŠå¤©è®°å½•è½¬æ¢æˆ Google API éœ€è¦çš„æ ¼å¼
    contents_payload = []
    for msg in messages:
        role = "user" if msg["role"] == "user" else "model"
        contents_payload.append({"role": role, "parts": [{"text": msg["content"]}]})
        
    data = {"contents": contents_payload}
    
    try:
        response = requests.post(url, headers=headers, data=json.dumps(data))
        if response.status_code == 200:
            return response.json()['candidates'][0]['content']['parts'][0]['text']
        else:
            return f"Error: {response.status_code} - {response.text}"
    except Exception as e:
        return f"Error: {e}"

# --- 6. åˆå§‹åˆ†æåŒºåŸŸ ---
if not st.session_state.analysis_done:
    user_idea = st.text_area("è¾“å…¥ä½ çš„åˆ›ä¸šæƒ³æ³•ï¼š", height=100, placeholder="ä¾‹å¦‚ï¼šæˆ‘æƒ³åšä¸€ä¸ªå¸®åŠ©å†…å‘è€…ç»ƒä¹ æ¼”è®²çš„ VR å·¥å…·...")
    
    if st.button("å¼€å§‹æ·±åº¦åˆ†æ") and api_key and user_idea:
        with st.spinner('æ­£åœ¨ç»“åˆä½ çš„ MBTI æ€§æ ¼è¿›è¡Œæ·±åº¦å‰–æ...'):
            # æ„å»ºè¶…çº§è¯¦ç»†çš„ Prompt
            initial_prompt = f"""
            ä½ æ˜¯ä¸€ä½ç²¾é€šå•†ä¸šåˆ†æå’Œå¿ƒç†å­¦çš„åˆ›ä¸šå¯¼å¸ˆã€‚
            
            ç”¨æˆ·ä¿¡æ¯ï¼š
            - åˆ›ä¸šç‚¹å­ï¼š"{user_idea}"
            - MBTI äººæ ¼ï¼š"{user_mbti}"
            
            è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
            1. **æ‰“åˆ†**ï¼šç»™å‡ºå¸‚åœºã€æŠ€æœ¯ã€ç«äº‰ä¸‰ä¸ªç»´åº¦çš„æ‰“åˆ† (0-100)ã€‚
            2. **æ·±åº¦åˆ†æ**ï¼šé’ˆå¯¹æ¯ä¸ªåˆ†æ•°ï¼Œè¯¦ç»†è§£é‡Šâ€œä¸ºä»€ä¹ˆè¿™ä¹ˆæ‰“åˆ†â€ï¼ŒæŒ‡å‡ºå…·ä½“ä¾æ®ã€‚
            3. **MBTI é€‚é…å»ºè®®**ï¼šç»“åˆç”¨æˆ·çš„ MBTI æ€§æ ¼ï¼Œç»™å‡ºå…·ä½“çš„æ‰§è¡Œå»ºè®®ã€‚
               - ä¾‹å¦‚ï¼šå¦‚æœæ˜¯ INTJï¼Œé‡ç‚¹è®²ç³»ç»Ÿæ¶æ„å’Œé•¿æœŸæˆ˜ç•¥ï¼›å¦‚æœæ˜¯ ENFPï¼Œé‡ç‚¹è®²ç¤¾ç¾¤è¿è¥å’Œæ„¿æ™¯ã€‚
               - æ¨èä¸€ç§æœ€é€‚åˆè¯¥æ€§æ ¼çš„â€œå•äººåˆ›ä¸šå·¥ä½œæµâ€ã€‚
            
            ã€é‡è¦ã€‘è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¿”å›ï¼Œä¸è¦åŠ  markdown æ ‡è®°ï¼š
            {{
                "scores": {{
                    "market": 85,
                    "tech": 60,
                    "competition": 90
                }},
                "analysis_text": "è¿™é‡Œæ”¾å…¥è¯¦ç»†çš„æ‰“åˆ†ç†ç”±åˆ†æ...",
                "mbti_advice": "è¿™é‡Œæ”¾å…¥é’ˆå¯¹ MBTI çš„å»ºè®®..."
            }}
            """
            
            # è°ƒç”¨ API
            response_text = call_gemini([{"role": "user", "content": initial_prompt}])
            
            # è§£æç»“æœ
            try:
                # æ¸…æ´—å¯èƒ½å­˜åœ¨çš„ markdown æ ‡è®°
                clean_text = response_text.replace("```json", "").replace("```", "").strip()
                result_data = json.loads(clean_text)
                
                # ä¿å­˜åˆ° Session State
                st.session_state.analysis_done = True
                st.session_state.current_scores = result_data['scores']
                
                # å°†åˆ†æç»“æœå­˜å…¥èŠå¤©è®°å½•çš„ç¬¬ä¸€æ¡
                st.session_state.messages.append({"role": "user", "content": f"æˆ‘çš„ç‚¹å­æ˜¯ï¼š{user_idea}ï¼Œæˆ‘æ˜¯ {user_mbti}"})
                
                # æ„å»ºä¸€ä¸ªæ¼‚äº®çš„å›å¤æ˜¾ç¤º
                ai_response_content = f"""
### ğŸ“Š æ·±åº¦è¯„ä¼°æŠ¥å‘Š

**ğŸ’° å¸‚åœºæ½œåŠ›**: {result_data['scores']['market']}/100
**ğŸ› ï¸ æŠ€æœ¯éš¾åº¦**: {result_data['scores']['tech']}/100
**âš”ï¸ ç«äº‰ç¨‹åº¦**: {result_data['scores']['competition']}/100

---
### ğŸ§ ä¸ºä»€ä¹ˆè¿™ä¹ˆæ‰“åˆ†ï¼Ÿ
{result_data['analysis_text']}

---
### ğŸ§˜ ä¸º {user_mbti} å®šåˆ¶çš„åˆ›ä¸šæŒ‡å—
{result_data['mbti_advice']}
                """
                st.session_state.messages.append({"role": "assistant", "content": ai_response_content})
                
                # å¼ºåˆ¶åˆ·æ–°é¡µé¢ä»¥è¿›å…¥èŠå¤©æ¨¡å¼
                st.rerun()
                
            except Exception as e:
                st.error("è§£ææ•°æ®å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚")
                st.expander("æŸ¥çœ‹åŸå§‹è¿”å›").write(response_text)

# --- 7. åˆ†æå®Œæˆåçš„å±•ç¤ºä¸èŠå¤©åŒºåŸŸ ---
else:
    # é¡¶éƒ¨æ˜¾ç¤ºåˆ†æ•°ä»ªè¡¨ç›˜ (å›ºå®šæ˜¾ç¤º)
    if st.session_state.current_scores:
        s = st.session_state.current_scores
        c1, c2, c3 = st.columns(3)
        c1.metric("ğŸ’° å¸‚åœºæ½œåŠ›", f"{s['market']}/100")
        c2.metric("ğŸ› ï¸ æŠ€æœ¯éš¾åº¦", f"{s['tech']}/100")
        c3.metric("âš”ï¸ ç«äº‰ç¨‹åº¦", f"{s['competition']}/100")
        st.markdown("---")

    # æ˜¾ç¤ºèŠå¤©å†å²
    for msg in st.session_state.messages:
        if msg["role"] != "user": # ç¬¬ä¸€æ¡ç”¨æˆ·è¾“å…¥ä¸é‡å¤æ˜¾ç¤ºåœ¨æ°”æ³¡é‡Œï¼Œåªæ˜¾ç¤º AI å›å¤
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])
        elif msg == st.session_state.messages[0]:
            pass # è·³è¿‡åˆå§‹ prompt çš„æ˜¾ç¤º
        else:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

    # èŠå¤©è¾“å…¥æ¡†
    if prompt := st.chat_input("é’ˆå¯¹ä»¥ä¸Šåˆ†æï¼Œä½ æœ‰ä»€ä¹ˆæƒ³è¿½é—®çš„ï¼Ÿ(ä¾‹å¦‚ï¼šæˆ‘è¯¥æ€ä¹ˆæ”¹è¿›æŠ€æœ¯åˆ†ï¼Ÿ)"):
        # 1. æ˜¾ç¤ºç”¨æˆ·é—®é¢˜
        with st.chat_message("user"):
            st.markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        # 2. AI æ€è€ƒå¹¶å›ç­”
        with st.chat_message("assistant"):
            with st.spinner("AI æ­£åœ¨æ€è€ƒ..."):
                response = call_gemini(st.session_state.messages)
                st.markdown(response)
        st.session_state.messages.append({"role": "assistant", "content": response})

    # é‡ç½®æŒ‰é’®
    if st.button("ğŸ”„ å¼€å§‹æ–°çš„åˆ†æ"):
        st.session_state.messages = []
        st.session_state.analysis_done = False
        st.session_state.current_scores = None
        st.rerun()
